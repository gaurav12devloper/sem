#stopwords
import nltk
nltk.download('stopwords')
nltk.download('punkt')
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
file=open('sample.txt')
send=file.read()
stop=set(stopwords.words('english'))
token=word_tokenize(send)
a=[]
for w in token:
    if w not in stop:
        a.append(w)
print("original sentence: ",token)
print("================================")
print("stop words: ",stop)
print("================================")
print("stop words removal : ",a)
print("================================")
print(" ".join(a))